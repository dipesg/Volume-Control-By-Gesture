# Volume-Control-By-Gesture
This is a simple python script which demonstrate how volume can be controlled by detecting hand using **Mediapipe** Framework to detect hand, ctypes, comtypes, pycaw and opencv-python.

### Demo
![v1](https://user-images.githubusercontent.com/75604769/167442267-6c1f0c09-ced1-491d-aee2-eb39dd9b7d4c.png)

![v2](https://user-images.githubusercontent.com/75604769/167442270-6aa79c5d-2ad1-4200-9dee-858dbd974ae4.png)

![v3](https://user-images.githubusercontent.com/75604769/167442281-41f7b62d-0f01-425d-8f57-eec870b1735d.png)

### How to Run?
Clone the repository.
```
git clone https://github.com/dipesg/Volume-Control-By-Gesture.git
```
Create virtual environment.
```
conda create -n venv python=3.7 -y
```
Activate Virtual environment.
```
conda activate venv
```
Install required dependencies.
```
pip install -r requirements.txt
```
Run the file in the command prompt.
```
python run VolumeControl.py
```

## Technologies Used
![](https://forthebadge.com/images/badges/made-with-python.svg)

[<img target="_blank" src="https://editor.analyticsvidhya.com/uploads/800882.png" width=200>](https://opencv.org/) [<img target="_blank" src="https://fiverr-res.cloudinary.com/images/q_auto,f_auto/gigs/200082652/original/76e46a8fd6ae4aa835e7ec3878276ff494b49017/solve-your-mediapipe-related-problems.jpeg" width=170>](https://www.dreamstime.com/illustration/nlp.html) 
